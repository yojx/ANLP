{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae481d90-49b6-4fb9-8680-85c0361e71d0",
   "metadata": {},
   "source": [
    "## Prepare the Labelled Log Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45edb88e-0227-4400-88f8-e92ce737e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64446dcd-a963-48d2-bbc1-48a070b43fb2",
   "metadata": {},
   "source": [
    "## Read Hadoop log File\n",
    "##### Each line of log comprises of the Date, Time, PID, Level, Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8799a243-4b7c-404e-95e0-67874f33fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read log data from the .log file\n",
    "with open('HDFS_5k.log', 'r') as log_file:\n",
    "    log_lines = log_file.readlines()  # Read all lines from the log file\n",
    "\n",
    "log_df = pd.DataFrame(log_lines, columns=['Log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0cf6d92-35a5-4f77-be4a-cd19b2202850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4519, 1)\n"
     ]
    }
   ],
   "source": [
    "print(log_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b8bbbbe-6010-43fb-b5ca-fe05b9973287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>081109 203518 143 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.19.102:54106 dest: /10.250.19.102:50010\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>081109 203518 35 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /mnt/hadoop/mapred/system/job_200811092030_0001/job.jar. blk_-1608999687919862906\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>081109 203519 143 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.10.6:40524 dest: /10.250.10.6:50010\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>081109 203519 145 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.14.224:42420 dest: /10.250.14.224:50010\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>081109 203519 145 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_-1608999687919862906 terminating\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                            Log\n",
       "0              081109 203518 143 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.19.102:54106 dest: /10.250.19.102:50010\\n\n",
       "1  081109 203518 35 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /mnt/hadoop/mapred/system/job_200811092030_0001/job.jar. blk_-1608999687919862906\\n\n",
       "2                  081109 203519 143 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.10.6:40524 dest: /10.250.10.6:50010\\n\n",
       "3              081109 203519 145 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.14.224:42420 dest: /10.250.14.224:50010\\n\n",
       "4                                       081109 203519 145 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_-1608999687919862906 terminating\\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "log_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0b2b3d-4893-4fc0-ad08-16b2ee18ea81",
   "metadata": {},
   "source": [
    "## Read Labels\n",
    "##### Each BlockId is labelled Normal or Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "972ce1b8-0dfd-40b0-b56d-df429d9682fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read anomaly labels from CSV\n",
    "anomaly_labels_df = pd.read_csv('./anomaly_label.csv')  # Contains 'BlockId' and 'Label'\n",
    "\n",
    "# Convert anomaly labels to a dictionary for quick lookup\n",
    "anomaly_labels_data = dict(zip(anomaly_labels_df['BlockId'], anomaly_labels_df['Label']))\n",
    "\n",
    "# Create a list to hold combined data\n",
    "combined_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "069cfe37-8186-42cd-b377-9613bbe759b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlockId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blk_7503483334202473044</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blk_-3544583377289625738</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blk_-9073992586687739851</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blk_7854771516489510256</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    BlockId    Label\n",
       "0  blk_-1608999687919862906   Normal\n",
       "1   blk_7503483334202473044   Normal\n",
       "2  blk_-3544583377289625738  Anomaly\n",
       "3  blk_-9073992586687739851   Normal\n",
       "4   blk_7854771516489510256   Normal"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba422a22-8e68-41db-a555-23b0191a60d2",
   "metadata": {},
   "source": [
    "## Associate Event Log and Labels\n",
    "##### Each BlockId is associated to a set of Events. Tag each Event to be either Normal or Anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88fdd689-3156-4f2d-b5a8-37a4797f66a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Log                   BlockId    Label\n",
      "0      081109 203518 143 INFO dfs.Data...  blk_-1608999687919862906   Normal\n",
      "1      081109 203518 35 INFO dfs.FSNam...  blk_-1608999687919862906   Normal\n",
      "2      081109 203519 143 INFO dfs.Data...  blk_-1608999687919862906   Normal\n",
      "3      081109 203519 145 INFO dfs.Data...  blk_-1608999687919862906   Normal\n",
      "4      081109 203519 145 INFO dfs.Data...  blk_-1608999687919862906   Normal\n",
      "...                                   ...                       ...      ...\n",
      "19407  081110 105225 19 INFO dfs.FSDat...    blk_872694497849122755  Anomaly\n",
      "19408  081110 105400 19 INFO dfs.FSDat...   blk_3947106522258141922  Anomaly\n",
      "19409  081110 105400 19 INFO dfs.FSDat...   blk_3947106522258141922  Anomaly\n",
      "19410  081110 105446 19 INFO dfs.FSDat...   blk_-774246298521956028   Normal\n",
      "19411  081110 105446 19 INFO dfs.FSDat...   blk_-774246298521956028   Normal\n",
      "\n",
      "[19412 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Process each log line\n",
    "for index, row in log_df.iterrows():\n",
    "    line = row['Log']\n",
    "    # Extract block IDs from the log line\n",
    "    block_ids = re.findall(r'blk_[\\-\\d]+', line)\n",
    "    \n",
    "    if block_ids:\n",
    "        # Get the label for each block ID found\n",
    "        for block_id in block_ids:\n",
    "            label = anomaly_labels_data.get(block_id, 'Unknown')\n",
    "            combined_data.append({'Log': line.strip(), 'BlockId': block_id, 'Label': label})\n",
    "\n",
    "# Convert combined data to a DataFrame\n",
    "combined_df = pd.DataFrame(combined_data)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "pd.set_option('display.max_colwidth', 35)\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48558e5-d762-42be-803d-1e9cc90d7fcd",
   "metadata": {},
   "source": [
    "## Clean the Data\n",
    "##### Remove Date, Time, and other unnecessary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76da9830-c6dc-4fdb-871c-5e4673c4c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.drop(['BlockId'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2367f715-bd90-4918-8c60-62cbd9564485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the logs\n",
    "def clean_log(log):\n",
    "    # Remove date and time (assumes format 'DDMMYY HHMMSS')\n",
    "    log = re.sub(r'^\\d{6} \\d{6} ', '', log)\n",
    "    # Remove all occurrences of 'blk_-xxx' patterns\n",
    "    log = re.sub(r'blk_-?\\d+', '', log)\n",
    "    return log.strip()\n",
    "\n",
    "# Apply the cleaning function to the 'Log' column\n",
    "combined_df['Log'] = combined_df['Log'].apply(clean_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c5bd1c2-453b-4b92-b285-af81e91c9994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143 INFO dfs.DataNode$DataXceiver: Receiving block  src: /10.250.19.102:54106 dest: /10.250.19.102:50010</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /mnt/hadoop/mapred/system/job_200811092030_0001/job.jar.</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143 INFO dfs.DataNode$DataXceiver: Receiving block  src: /10.250.10.6:40524 dest: /10.250.10.6:50010</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145 INFO dfs.DataNode$DataXceiver: Receiving block  src: /10.250.14.224:42420 dest: /10.250.14.224:50010</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block  terminating</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                   Log  \\\n",
       "0             143 INFO dfs.DataNode$DataXceiver: Receiving block  src: /10.250.19.102:54106 dest: /10.250.19.102:50010   \n",
       "1  35 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /mnt/hadoop/mapred/system/job_200811092030_0001/job.jar.   \n",
       "2                 143 INFO dfs.DataNode$DataXceiver: Receiving block  src: /10.250.10.6:40524 dest: /10.250.10.6:50010   \n",
       "3             145 INFO dfs.DataNode$DataXceiver: Receiving block  src: /10.250.14.224:42420 dest: /10.250.14.224:50010   \n",
       "4                                      145 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block  terminating   \n",
       "\n",
       "    Label  \n",
       "0  Normal  \n",
       "1  Normal  \n",
       "2  Normal  \n",
       "3  Normal  \n",
       "4  Normal  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f38c377c-0d08-444a-adb9-05767304a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv('combined_logs_with_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2359af-929f-40a3-986c-0aa4e66ee3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
